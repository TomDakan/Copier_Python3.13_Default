[project]
name = "Default"
version = "0.1.0"
description = "Main template for bootstrapping python projects with testing, linting/formatting, and docs generation."
authors = [
    {name = "Thomas Dakan", email = "tomdakan@gmail.com"},
]
dependencies = ["pydantic>=2.12.2", "pydantic-settings>=2.11.0"]
requires-python = ">=3.13"
readme = "README.md"
license = {text = "LicenseRef-Proprietary"}

[tool.commitizen]
name = "cz_conventional_commits"
tag_format = "$version"
version_scheme = "semver2"
version_provider = "pep621"
update_changelog_on_bump = true
major_version_zero = true
changelog_file = "CHANGELOG.md"

[tool.pdm]
distribution = false

[tool.pdm.scripts]
# Generate a test project from the template in the current directory
generate = { cmd = "copier copy . ./test-output --force --trust --defaults -a run_install=false", help = "Generate a test project" }

# Run the QA suite inside the generated project
test-generated = { shell = "cd ./test-output/my_new_project && pdm install --dev && pdm run qa", help = "Install and run QA suite in the generated project" }

# Clean up the generated test directory
clean = { cmd = "rm -rf ./test-output", help = "Remove the generated test project" }

test-template = { composite = ["generate", "test-generated", "clean"] }

[dependency-groups]
dev = [
    "commitizen>=4.9.1",
    "pre-commit>=4.3.0",
    "pytest>=8.4.2",
    "copier>=9.10.3",
    "coverage>=7.11.0",
    "pytest-cov>=7.0.0",
]

[tool.ruff]
line-length = 120
target-version = "py313"

[tool.ruff.lint]
select = [
    "E",  # pycodestyle errors
    "W",  # pycodestyle warnings
    "F",  # pyflakes
    "I",  # isort (import sorting)
    "B",  # flake8-bugbear
    "C4", # flake8-comprehensions
    "UP", # pyupgrade
]

[tool.pytest.ini_options]
minversion = "6.0"
# Add flags to run coverage on the 'tests' directory
addopts = "-ra -q --cov=tests --cov-report=term-missing"
testpaths = [
    "tests",
]

[tool.coverage.run]
# Specify that we are measuring coverage of the test files themselves
source = ["tests"]

[tool.coverage.report]
# Optional: Fail the test run if coverage is below 100%
fail_under = 100
show_missing = true